{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-13T03:04:29.389353Z",
     "start_time": "2023-06-13T03:04:29.345472Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sDQFnbtgnkEy",
    "outputId": "5a9668d3-0449-4a02-aa30-b9c1df015bd8"
   },
   "outputs": [],
   "source": [
    "# !pip install torchinfo\n",
    "# !pip install torcheval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-13T03:04:29.485098Z",
     "start_time": "2023-06-13T03:04:29.394339Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1Elu_juQn4CK",
    "outputId": "d213d341-c708-4af4-d23a-2271b97d9368"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-13T03:04:29.518022Z",
     "start_time": "2023-06-13T03:04:29.499062Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BmjD3iEvn8FJ",
    "outputId": "2095fb73-60ca-491c-aa52-fdb56920595b"
   },
   "outputs": [],
   "source": [
    "# %cd /content/drive/MyDrive/2023_AI_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-13T09:39:21.509078Z",
     "start_time": "2023-06-13T09:39:18.332920Z"
    },
    "id": "gQ6p9PJingpx"
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import h5py\n",
    "import numpy as np\n",
    "from torchinfo import summary\n",
    "import math\n",
    "from torch.autograd import Variable\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-13T09:39:27.199471Z",
     "start_time": "2023-06-13T09:39:21.563693Z"
    },
    "id": "A5HdtpNEngp3"
   },
   "outputs": [],
   "source": [
    "# custom module\n",
    "import model, pamap_dataloader, train_model, test_model\n",
    "import importlib\n",
    "importlib.reload(model)\n",
    "importlib.reload(pamap_dataloader)\n",
    "importlib.reload(train_model)\n",
    "importlib.reload(test_model)\n",
    "from model import *\n",
    "from data import *\n",
    "from pamap_dataloader import *\n",
    "from train_model import train\n",
    "from test_model import test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QZEy4lrOngp4"
   },
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-13T09:39:27.277032Z",
     "start_time": "2023-06-13T09:39:27.253099Z"
    },
    "id": "NEiAJ3EHngp_"
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"root\" : \"./data/pickles/\",\n",
    "    \"train_feature\" : \"PAMAP2_feature.pickle\",\n",
    "    \"train_target\" : \"PAMAP2_target.pickle\",\n",
    "    \"test_feature\" : \"PAMAP2_feature_test.pickle\",\n",
    "    \"test_target\" : \"PAMAP2_target_test.pickle\",\n",
    "    \"labelencodedict\" :  { 1 : 0,\n",
    "                   3 : 1,\n",
    "                   4 : 2,\n",
    "                   6 : 3,\n",
    "                   7 : 4,\n",
    "                   16 : 5,\n",
    "                   17 : 6\n",
    "                   },\n",
    "    \"epochs\" : 3000,\n",
    "    \"learning_rate\" : 1e-4,\n",
    "    # model \n",
    "    \"first_out_channels\" : 32,\n",
    "    \"first_kernel_size\" : 5,\n",
    "    \"second_in_channels\" : 32,\n",
    "    \"second_out_channels\" : 16,\n",
    "    \"second_kernel_size\" : 3,\n",
    "    \"dim_model\" : 128,\n",
    "    \"dim_inner\" : 256,\n",
    "    \"num_heads\" : 8,\n",
    "    \"dropout_rate\" : 0.15,\n",
    "    \"squeeze_factor\" : 2,\n",
    "    \"sec_kernel_size\" : 3,\n",
    "    \"sec_stride\" : 1,\n",
    "    \"N\" : 3,\n",
    "    \"gamma\" : 2,\n",
    "    \"u\" : 2,     \n",
    "    \"weight_decay\" : 0.1,\n",
    "    \"device\" : torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g3kVFy46ngqB"
   },
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-13T09:39:22.060Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 381
    },
    "id": "jtStFRVAngqC",
    "outputId": "53972f03-1b80-46a9-fcb9-5807b71e18d2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yuins\\Hanyang_23_1st\\AI\\model.py:40: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  attention_prob = torch.nn.functional.softmax(scaled_att_score)\n",
      "C:\\Users\\yuins\\Hanyang_23_1st\\AI\\model.py:255: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  attention_prob = torch.nn.functional.softmax(scaled_att_score)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 1.0578, Train acc: 97.5510%, F1 macro: 0.9140\n",
      "Epoch: 1, Loss: 0.7992, Train acc: 99.1837%, F1 macro: 0.9711\n",
      "Epoch: 2, Loss: 0.8081, Train acc: 98.3673%, F1 macro: 0.9444\n",
      "Epoch: 3, Loss: 0.6659, Train acc: 97.5510%, F1 macro: 0.9163\n",
      "Epoch: 4, Loss: 0.5327, Train acc: 95.9184%, F1 macro: 0.8632\n",
      "Epoch: 5, Loss: 0.4364, Train acc: 97.5510%, F1 macro: 0.9116\n",
      "Epoch: 6, Loss: 0.4370, Train acc: 99.1837%, F1 macro: 0.9711\n",
      "Epoch: 7, Loss: 0.3500, Train acc: 99.1837%, F1 macro: 0.9711\n",
      "Epoch: 8, Loss: 0.3132, Train acc: 98.3673%, F1 macro: 0.9423\n",
      "Epoch: 9, Loss: 0.1957, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 10, Loss: 0.1520, Train acc: 99.1837%, F1 macro: 0.9711\n",
      "Epoch: 11, Loss: 0.1441, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 12, Loss: 0.0738, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 13, Loss: 0.0755, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 14, Loss: 0.0794, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 15, Loss: 0.0423, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 16, Loss: 0.0338, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 17, Loss: 0.0260, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 18, Loss: 0.0255, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 19, Loss: 0.0141, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 20, Loss: 0.0237, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 21, Loss: 0.0173, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 22, Loss: 0.0132, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 23, Loss: 0.0084, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 24, Loss: 0.0092, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 25, Loss: 0.0100, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 26, Loss: 0.0074, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 27, Loss: 0.0055, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 28, Loss: 0.0068, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 29, Loss: 0.0085, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 30, Loss: 0.0033, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 31, Loss: 0.0050, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 32, Loss: 0.0029, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 33, Loss: 0.0062, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 34, Loss: 0.0044, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 35, Loss: 0.0031, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 36, Loss: 0.0037, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 37, Loss: 0.0044, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 38, Loss: 0.0043, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 39, Loss: 0.0041, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 40, Loss: 0.0034, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 41, Loss: 0.0037, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 42, Loss: 0.0050, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 43, Loss: 0.0025, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 44, Loss: 0.0058, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 45, Loss: 0.0045, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 46, Loss: 0.0026, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 47, Loss: 0.0043, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 48, Loss: 0.0041, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 49, Loss: 0.0046, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 50, Loss: 0.0037, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 51, Loss: 0.0037, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 52, Loss: 0.0045, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 53, Loss: 0.0034, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 54, Loss: 0.0029, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 55, Loss: 0.0056, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 56, Loss: 0.0029, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 57, Loss: 0.0032, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 58, Loss: 0.0024, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 59, Loss: 0.0023, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 60, Loss: 0.0038, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 61, Loss: 0.0054, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 62, Loss: 0.0048, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 63, Loss: 0.0057, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 64, Loss: 0.0038, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 65, Loss: 0.0047, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 66, Loss: 0.0050, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 67, Loss: 0.0048, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 68, Loss: 0.0034, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 69, Loss: 0.0057, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 70, Loss: 0.0068, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 71, Loss: 0.0039, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 72, Loss: 0.0045, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 73, Loss: 0.0067, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 74, Loss: 0.0063, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 75, Loss: 0.0066, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 76, Loss: 0.0063, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 77, Loss: 0.0060, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 78, Loss: 0.0069, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 79, Loss: 0.0042, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 80, Loss: 0.0058, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 81, Loss: 0.0051, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 82, Loss: 0.0067, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 83, Loss: 0.0059, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 84, Loss: 0.0052, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 85, Loss: 0.0045, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 86, Loss: 0.0036, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 87, Loss: 0.0032, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 88, Loss: 0.0055, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 89, Loss: 0.0036, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 90, Loss: 0.0038, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 91, Loss: 0.0050, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 92, Loss: 0.0039, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 93, Loss: 0.0047, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 94, Loss: 0.0063, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 95, Loss: 0.0081, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 96, Loss: 0.0077, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 97, Loss: 0.0037, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 98, Loss: 0.0043, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 99, Loss: 0.0031, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 100, Loss: 0.0067, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 101, Loss: 0.0057, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 102, Loss: 0.0079, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 103, Loss: 0.0047, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 104, Loss: 0.0053, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 105, Loss: 0.0046, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 106, Loss: 0.0063, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 107, Loss: 0.0048, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 108, Loss: 0.0065, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 109, Loss: 0.0109, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 110, Loss: 0.0037, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 111, Loss: 0.0098, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 112, Loss: 0.0055, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 113, Loss: 0.0041, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 114, Loss: 0.0042, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 115, Loss: 0.0038, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 116, Loss: 0.0047, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 117, Loss: 0.0038, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 118, Loss: 0.0047, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 119, Loss: 0.0047, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 120, Loss: 0.0029, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 121, Loss: 0.0036, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 122, Loss: 0.0038, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 123, Loss: 0.0033, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 124, Loss: 0.0048, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 125, Loss: 0.0026, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 126, Loss: 0.0034, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 127, Loss: 0.0028, Train acc: 100.0000%, F1 macro: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 128, Loss: 0.0033, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 129, Loss: 0.0029, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 130, Loss: 0.0033, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 131, Loss: 0.0037, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 132, Loss: 0.0041, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 133, Loss: 0.0035, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 134, Loss: 0.0024, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 135, Loss: 0.0033, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 136, Loss: 0.0027, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 137, Loss: 0.0045, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 138, Loss: 0.0024, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 139, Loss: 0.0035, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 140, Loss: 0.0033, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 141, Loss: 0.0037, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 142, Loss: 0.0036, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 143, Loss: 0.0076, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 144, Loss: 0.0032, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 145, Loss: 0.0035, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 146, Loss: 0.0027, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 147, Loss: 0.0033, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 148, Loss: 0.0044, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 149, Loss: 0.0041, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 150, Loss: 0.0034, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 151, Loss: 0.0055, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 152, Loss: 0.0044, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 153, Loss: 0.0048, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 154, Loss: 0.0029, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 155, Loss: 0.0036, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 156, Loss: 0.0088, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 157, Loss: 0.0037, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 158, Loss: 0.0037, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 159, Loss: 0.0042, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 160, Loss: 0.0047, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 161, Loss: 0.0038, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 162, Loss: 0.0037, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 163, Loss: 0.0038, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 164, Loss: 0.0046, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 165, Loss: 0.0033, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 166, Loss: 0.0042, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 167, Loss: 0.0025, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 168, Loss: 0.0039, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 169, Loss: 0.0052, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 170, Loss: 0.0031, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 171, Loss: 0.0041, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 172, Loss: 0.0041, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 173, Loss: 0.0038, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 174, Loss: 0.0048, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 175, Loss: 0.0027, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 176, Loss: 0.0060, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 177, Loss: 0.0032, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 178, Loss: 0.0072, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 179, Loss: 0.0044, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 180, Loss: 0.0067, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 181, Loss: 0.0051, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 182, Loss: 0.0040, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 183, Loss: 0.0085, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 184, Loss: 0.0030, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 185, Loss: 0.0085, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 186, Loss: 0.0059, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 187, Loss: 0.0038, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 188, Loss: 0.0076, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 189, Loss: 0.0040, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 190, Loss: 0.0037, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 191, Loss: 0.0033, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 192, Loss: 0.0101, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 193, Loss: 0.0035, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 194, Loss: 0.0033, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 195, Loss: 0.0074, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 196, Loss: 0.0033, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 197, Loss: 0.0028, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 198, Loss: 0.0023, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 199, Loss: 0.0039, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 200, Loss: 0.0031, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 201, Loss: 0.0021, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 202, Loss: 0.0030, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 203, Loss: 0.0027, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 204, Loss: 0.0028, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 205, Loss: 0.0024, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 206, Loss: 0.0029, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 207, Loss: 0.0019, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 208, Loss: 0.0045, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 209, Loss: 0.0018, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 210, Loss: 0.0017, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 211, Loss: 0.0028, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 212, Loss: 0.0025, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 213, Loss: 0.0029, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 214, Loss: 0.0040, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 215, Loss: 0.0026, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 216, Loss: 0.0019, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 217, Loss: 0.0024, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 218, Loss: 0.0026, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 219, Loss: 0.0021, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 220, Loss: 0.0036, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 221, Loss: 0.0036, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 222, Loss: 0.0028, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 223, Loss: 0.0028, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 224, Loss: 0.0023, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 225, Loss: 0.0021, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 226, Loss: 0.0027, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 227, Loss: 0.0025, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 228, Loss: 0.0025, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 229, Loss: 0.0019, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 230, Loss: 0.0024, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 231, Loss: 0.0033, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 232, Loss: 0.0023, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 233, Loss: 0.0027, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 234, Loss: 0.0030, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 235, Loss: 0.0022, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 236, Loss: 0.0031, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 237, Loss: 0.0034, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 238, Loss: 0.0032, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 239, Loss: 0.0041, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 240, Loss: 0.0027, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 241, Loss: 0.0033, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 242, Loss: 0.0035, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 243, Loss: 0.0023, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 244, Loss: 0.0043, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 245, Loss: 0.0032, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 246, Loss: 0.0047, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 247, Loss: 0.0033, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 248, Loss: 0.0032, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 249, Loss: 0.0035, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 250, Loss: 0.0028, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 251, Loss: 0.0024, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 252, Loss: 0.0033, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 253, Loss: 0.0024, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 254, Loss: 0.0028, Train acc: 100.0000%, F1 macro: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 255, Loss: 0.0021, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 256, Loss: 0.0035, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 257, Loss: 0.0022, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 258, Loss: 0.0025, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 259, Loss: 0.0022, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 260, Loss: 0.0035, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 261, Loss: 0.0020, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 262, Loss: 0.0022, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 263, Loss: 0.0024, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 264, Loss: 0.0033, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 265, Loss: 0.0027, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 266, Loss: 0.0023, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 267, Loss: 0.0035, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 268, Loss: 0.0043, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 269, Loss: 0.0050, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 270, Loss: 0.0176, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 271, Loss: 0.1955, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 272, Loss: 0.1260, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 273, Loss: 0.0712, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 274, Loss: 0.0561, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 275, Loss: 0.0201, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 276, Loss: 0.0215, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 277, Loss: 0.0162, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 278, Loss: 0.0132, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 279, Loss: 0.0111, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 280, Loss: 0.0091, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 281, Loss: 0.0063, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 282, Loss: 0.0050, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 283, Loss: 0.0074, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 284, Loss: 0.0028, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 285, Loss: 0.0030, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 286, Loss: 0.0029, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 287, Loss: 0.0025, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 288, Loss: 0.0017, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 289, Loss: 0.0010, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 290, Loss: 0.0017, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 291, Loss: 0.0008, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 292, Loss: 0.0009, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 293, Loss: 0.0014, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 294, Loss: 0.0010, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 295, Loss: 0.0010, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 296, Loss: 0.0011, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 297, Loss: 0.0011, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 298, Loss: 0.0008, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 299, Loss: 0.0010, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 300, Loss: 0.0007, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 301, Loss: 0.0007, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 302, Loss: 0.0006, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 303, Loss: 0.0007, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 304, Loss: 0.0013, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 305, Loss: 0.0010, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 306, Loss: 0.0010, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 307, Loss: 0.0009, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 308, Loss: 0.0010, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 309, Loss: 0.0011, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 310, Loss: 0.0005, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 311, Loss: 0.0007, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 312, Loss: 0.0009, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 313, Loss: 0.0009, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 314, Loss: 0.0011, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 315, Loss: 0.0013, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 316, Loss: 0.0012, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 317, Loss: 0.0012, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 318, Loss: 0.0010, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 319, Loss: 0.0011, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 320, Loss: 0.0013, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 321, Loss: 0.0013, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 322, Loss: 0.0007, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 323, Loss: 0.0014, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 324, Loss: 0.0011, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 325, Loss: 0.0011, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 326, Loss: 0.0014, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 327, Loss: 0.0012, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 328, Loss: 0.0018, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 329, Loss: 0.0014, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 330, Loss: 0.0016, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 331, Loss: 0.0009, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 332, Loss: 0.0018, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 333, Loss: 0.0019, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 334, Loss: 0.0015, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 335, Loss: 0.0018, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 336, Loss: 0.0014, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 337, Loss: 0.0013, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 338, Loss: 0.0011, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 339, Loss: 0.0013, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 340, Loss: 0.0017, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 341, Loss: 0.0011, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 342, Loss: 0.0016, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 343, Loss: 0.0017, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 344, Loss: 0.0017, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 345, Loss: 0.0016, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 346, Loss: 0.0020, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 347, Loss: 0.0015, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 348, Loss: 0.0024, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 349, Loss: 0.0018, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 350, Loss: 0.0021, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 351, Loss: 0.0012, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 352, Loss: 0.0014, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 353, Loss: 0.0015, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 354, Loss: 0.0015, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 355, Loss: 0.0022, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 356, Loss: 0.0018, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 357, Loss: 0.0014, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 358, Loss: 0.0013, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 359, Loss: 0.0015, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 360, Loss: 0.0018, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 361, Loss: 0.0017, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 362, Loss: 0.0014, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 363, Loss: 0.0013, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 364, Loss: 0.0014, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 365, Loss: 0.0016, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 366, Loss: 0.0016, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 367, Loss: 0.0017, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 368, Loss: 0.0015, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 369, Loss: 0.0013, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 370, Loss: 0.0021, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 371, Loss: 0.0031, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 372, Loss: 0.0017, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 373, Loss: 0.0014, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 374, Loss: 0.0017, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 375, Loss: 0.0019, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 376, Loss: 0.0013, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 377, Loss: 0.0012, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 378, Loss: 0.0014, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 379, Loss: 0.0014, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 380, Loss: 0.0013, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 381, Loss: 0.0016, Train acc: 100.0000%, F1 macro: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 382, Loss: 0.0018, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 383, Loss: 0.0021, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 384, Loss: 0.0027, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 385, Loss: 0.0011, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 386, Loss: 0.0016, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 387, Loss: 0.0016, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 388, Loss: 0.0014, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 389, Loss: 0.0020, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 390, Loss: 0.0012, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 391, Loss: 0.0019, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 392, Loss: 0.0013, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 393, Loss: 0.0018, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 394, Loss: 0.0017, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 395, Loss: 0.0019, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 396, Loss: 0.0012, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 397, Loss: 0.0016, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 398, Loss: 0.0017, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 399, Loss: 0.0017, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 400, Loss: 0.0019, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 401, Loss: 0.0017, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 402, Loss: 0.0013, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 403, Loss: 0.0014, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 404, Loss: 0.0019, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 405, Loss: 0.0015, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 406, Loss: 0.0016, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 407, Loss: 0.0017, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 408, Loss: 0.0016, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 409, Loss: 0.0012, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 410, Loss: 0.0015, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 411, Loss: 0.0014, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 412, Loss: 0.0011, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 413, Loss: 0.0012, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 414, Loss: 0.0015, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 415, Loss: 0.0013, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 416, Loss: 0.0021, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 417, Loss: 0.0013, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 418, Loss: 0.0017, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 419, Loss: 0.0016, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 420, Loss: 0.0012, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 421, Loss: 0.0016, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 422, Loss: 0.0010, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 423, Loss: 0.0009, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 424, Loss: 0.0017, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 425, Loss: 0.0011, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 426, Loss: 0.0009, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 427, Loss: 0.0016, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 428, Loss: 0.0010, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 429, Loss: 0.0013, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 430, Loss: 0.0012, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 431, Loss: 0.0010, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 432, Loss: 0.0014, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 433, Loss: 0.0010, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 434, Loss: 0.0016, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 435, Loss: 0.0010, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 436, Loss: 0.0017, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 437, Loss: 0.0013, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 438, Loss: 0.0017, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 439, Loss: 0.0018, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 440, Loss: 0.0014, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 441, Loss: 0.0011, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 442, Loss: 0.0013, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 443, Loss: 0.0012, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 444, Loss: 0.0012, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 445, Loss: 0.0013, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 446, Loss: 0.0011, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 447, Loss: 0.0010, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 448, Loss: 0.0013, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 449, Loss: 0.0013, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 450, Loss: 0.0011, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 451, Loss: 0.0012, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 452, Loss: 0.0012, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 453, Loss: 0.0016, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 454, Loss: 0.0014, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 455, Loss: 0.0015, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 456, Loss: 0.0013, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 457, Loss: 0.0011, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 458, Loss: 0.0013, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 459, Loss: 0.0011, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 460, Loss: 0.0012, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 461, Loss: 0.0010, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 462, Loss: 0.0012, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 463, Loss: 0.0011, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 464, Loss: 0.0011, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 465, Loss: 0.0015, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 466, Loss: 0.0016, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 467, Loss: 0.0014, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 468, Loss: 0.0013, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 469, Loss: 0.0016, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 470, Loss: 0.0024, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 471, Loss: 0.0039, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 472, Loss: 0.0173, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 473, Loss: 0.0712, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 474, Loss: 0.2446, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 475, Loss: 0.1034, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 476, Loss: 0.1139, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 477, Loss: 0.0459, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 478, Loss: 0.0381, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 479, Loss: 0.0232, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 480, Loss: 0.0143, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 481, Loss: 0.0109, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 482, Loss: 0.0064, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 483, Loss: 0.0047, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 484, Loss: 0.0034, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 485, Loss: 0.0024, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 486, Loss: 0.0023, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 487, Loss: 0.0016, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 488, Loss: 0.0016, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 489, Loss: 0.0010, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 490, Loss: 0.0008, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 491, Loss: 0.0013, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 492, Loss: 0.0009, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 493, Loss: 0.0006, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 494, Loss: 0.0005, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 495, Loss: 0.0005, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 496, Loss: 0.0007, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 497, Loss: 0.0007, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 498, Loss: 0.0005, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 499, Loss: 0.0010, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 500, Loss: 0.0008, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 501, Loss: 0.0004, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 502, Loss: 0.0005, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 503, Loss: 0.0005, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 504, Loss: 0.0004, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 505, Loss: 0.0004, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 506, Loss: 0.0005, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 507, Loss: 0.0006, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 508, Loss: 0.0005, Train acc: 100.0000%, F1 macro: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 509, Loss: 0.0003, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 510, Loss: 0.0004, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 511, Loss: 0.0005, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 512, Loss: 0.0005, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 513, Loss: 0.0006, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 514, Loss: 0.0004, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 515, Loss: 0.0004, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 516, Loss: 0.0004, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 517, Loss: 0.0005, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 518, Loss: 0.0004, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 519, Loss: 0.0005, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 520, Loss: 0.0005, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 521, Loss: 0.0006, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 522, Loss: 0.0004, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 523, Loss: 0.0007, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 524, Loss: 0.0007, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 525, Loss: 0.0005, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 526, Loss: 0.0006, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 527, Loss: 0.0005, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 528, Loss: 0.0007, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 529, Loss: 0.0004, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 530, Loss: 0.0010, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 531, Loss: 0.0006, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 532, Loss: 0.0007, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 533, Loss: 0.0006, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 534, Loss: 0.0005, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 535, Loss: 0.0010, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 536, Loss: 0.0006, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 537, Loss: 0.0008, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 538, Loss: 0.0007, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 539, Loss: 0.0006, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 540, Loss: 0.0010, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 541, Loss: 0.0007, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 542, Loss: 0.0008, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 543, Loss: 0.0007, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 544, Loss: 0.0013, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 545, Loss: 0.0013, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 546, Loss: 0.0011, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 547, Loss: 0.0005, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 548, Loss: 0.0010, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 549, Loss: 0.0008, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 550, Loss: 0.0008, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 551, Loss: 0.0005, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 552, Loss: 0.0007, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 553, Loss: 0.0006, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 554, Loss: 0.0007, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 555, Loss: 0.0014, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 556, Loss: 0.0010, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 557, Loss: 0.0009, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 558, Loss: 0.0011, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 559, Loss: 0.0007, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 560, Loss: 0.0008, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 561, Loss: 0.0016, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 562, Loss: 0.0008, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 563, Loss: 0.0007, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 564, Loss: 0.0008, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 565, Loss: 0.0008, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 566, Loss: 0.0008, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 567, Loss: 0.0009, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 568, Loss: 0.0006, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 569, Loss: 0.0012, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 570, Loss: 0.0009, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 571, Loss: 0.0009, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 572, Loss: 0.0008, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 573, Loss: 0.0009, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 574, Loss: 0.0010, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 575, Loss: 0.0010, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 576, Loss: 0.0012, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 577, Loss: 0.0009, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 578, Loss: 0.0012, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 579, Loss: 0.0012, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 580, Loss: 0.0007, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 581, Loss: 0.0011, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 582, Loss: 0.0010, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 583, Loss: 0.0010, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 584, Loss: 0.0018, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 585, Loss: 0.0007, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 586, Loss: 0.0010, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 587, Loss: 0.0010, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 588, Loss: 0.0012, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 589, Loss: 0.0018, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 590, Loss: 0.0011, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 591, Loss: 0.0010, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 592, Loss: 0.0007, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 593, Loss: 0.0009, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 594, Loss: 0.0009, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 595, Loss: 0.0011, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 596, Loss: 0.0011, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 597, Loss: 0.0010, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 598, Loss: 0.0012, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 599, Loss: 0.0010, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 600, Loss: 0.0007, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 601, Loss: 0.0010, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 602, Loss: 0.0010, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 603, Loss: 0.0009, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 604, Loss: 0.0015, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 605, Loss: 0.0009, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 606, Loss: 0.0013, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 607, Loss: 0.0008, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 608, Loss: 0.0012, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 609, Loss: 0.0012, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 610, Loss: 0.0008, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 611, Loss: 0.0009, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 612, Loss: 0.0012, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 613, Loss: 0.0010, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 614, Loss: 0.0014, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 615, Loss: 0.0009, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 616, Loss: 0.0010, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 617, Loss: 0.0009, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 618, Loss: 0.0008, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 619, Loss: 0.0012, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 620, Loss: 0.0011, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 621, Loss: 0.0010, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 622, Loss: 0.0011, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 623, Loss: 0.0007, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 624, Loss: 0.0007, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 625, Loss: 0.0008, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 626, Loss: 0.0009, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 627, Loss: 0.0010, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 628, Loss: 0.0014, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 629, Loss: 0.0008, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 630, Loss: 0.0012, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 631, Loss: 0.0011, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 632, Loss: 0.0007, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 633, Loss: 0.0019, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 634, Loss: 0.0015, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 635, Loss: 0.0012, Train acc: 100.0000%, F1 macro: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 636, Loss: 0.0008, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 637, Loss: 0.0011, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 638, Loss: 0.0008, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 639, Loss: 0.0009, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 640, Loss: 0.0008, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 641, Loss: 0.0011, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 642, Loss: 0.0011, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 643, Loss: 0.0012, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 644, Loss: 0.0014, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 645, Loss: 0.0009, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 646, Loss: 0.0009, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 647, Loss: 0.0008, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 648, Loss: 0.0008, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 649, Loss: 0.0009, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 650, Loss: 0.0014, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 651, Loss: 0.0009, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 652, Loss: 0.0010, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 653, Loss: 0.0012, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 654, Loss: 0.0012, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 655, Loss: 0.0007, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 656, Loss: 0.0007, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 657, Loss: 0.0011, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 658, Loss: 0.0007, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 659, Loss: 0.0008, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 660, Loss: 0.0009, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 661, Loss: 0.0010, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 662, Loss: 0.0006, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 663, Loss: 0.0010, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 664, Loss: 0.0007, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 665, Loss: 0.0008, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 666, Loss: 0.0008, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 667, Loss: 0.0008, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 668, Loss: 0.0006, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 669, Loss: 0.0007, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 670, Loss: 0.0008, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 671, Loss: 0.0007, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 672, Loss: 0.0010, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 673, Loss: 0.0009, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 674, Loss: 0.0009, Train acc: 100.0000%, F1 macro: 1.0000\n",
      "Epoch: 675, Loss: 0.0008, Train acc: 100.0000%, F1 macro: 1.0000\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    epochs = config[\"epochs\"]\n",
    "    learning_rate = config[\"learning_rate\"]\n",
    "    weight_decay = config[\"weight_decay\"]\n",
    "    X_train, y_train, train_y, X_test, y_test, test_y = load_dataset(config)\n",
    "    \n",
    "    X_train = X_train.double()\n",
    "    X_test = X_test.double()\n",
    "    config[\"num_samples\"] = X_train.shape[0]\n",
    "    config[\"first_in_channels\"] = X_train.shape[1]\n",
    "    config[\"L\"] = X_train.shape[2]\n",
    "    config[\"length\"] = X_train.shape[2]\n",
    "    \n",
    "    md = Net(\n",
    "                dim_model = config[\"dim_model\"],\n",
    "                gamma = config[\"gamma\"],\n",
    "                u = config[\"u\"],\n",
    "                ys = y_train,\n",
    "                first_in_channels = config[\"first_in_channels\"],\n",
    "                first_out_channels = config[\"first_out_channels\"],\n",
    "                first_kernel_size = config[\"first_kernel_size\"],\n",
    "                second_in_channels = config[\"second_in_channels\"],\n",
    "                second_out_channels = config[\"second_out_channels\"],\n",
    "                second_kernel_size = config[\"second_kernel_size\"],\n",
    "                N = config[\"N\"],  #slice\n",
    "                L = config[\"L\"], # slice\n",
    "                dim_inner = config[\"dim_inner\"],\n",
    "                num_samples = config[\"num_samples\"], \n",
    "                length = config[\"length\"], \n",
    "                num_heads = config[\"num_heads\"],\n",
    "                dropout_rate = config[\"dropout_rate\"],\n",
    "                squeeze_factor = config[\"squeeze_factor\"],\n",
    "                sec_kernel_size = config[\"sec_kernel_size\"],\n",
    "                sec_stride = config[\"sec_stride\"],\n",
    "                num_classes = len(config[\"labelencodedict\"].keys())).to(config['device'])\n",
    "    optimizer = torch.optim.Adam(md.parameters(),weight_decay=weight_decay, lr=learning_rate)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    \n",
    "    train_loss, train_acc, train_f1  = train(X_train, train_y, optimizer, model = md, epochs = epochs, f1=True)\n",
    "    md.ys = y_test\n",
    "    test_loss, test_acc, test_f1  = test(X_test, test_y, model = md, f1 = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize = (10,6))\n",
    "plt.ylim([-0.1, 1.5])\n",
    "plt.title(\"Train Loss\", fontsize = 20)\n",
    "plt.xlabel(\"Epochs\", fontsize=15)\n",
    "plt.ylabel(\"Loss\", fontsize=15)\n",
    "plt.axhline(1, alpha = 0.1, color = \"black\", linestyle = \"--\")\n",
    "plt.plot([i.cpu().detach().numpy() for i in train_loss])\n",
    "\n",
    "\n",
    "plt.figure(figsize = (10,6))\n",
    "plt.ylim([90, 102])\n",
    "plt.title(\"Train Accuracy\", fontsize = 20)\n",
    "plt.xlabel(\"Epochs\", fontsize=15)\n",
    "plt.ylabel(\"Accuracy\", fontsize=15)\n",
    "plt.axhline(100, alpha = 0.1, color = \"black\", linestyle = \"--\")\n",
    "plt.plot([i.cpu().detach().numpy() for i in train_acc])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "\n",
    "model_dimreduce = TSNE(n_components=2, learning_rate='auto',\n",
    "                  init='pca', perplexity=3)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "for i in range(len(train_representation)):\n",
    "    _rep = train_representation[i].cpu().detach().numpy()\n",
    "    _class = train_prototypes[i].squeeze(dim =1).cpu().detach().numpy()\n",
    "\n",
    "    _rep_tsne = model_dimreduce.fit_transform(_rep)\n",
    "    _class_tsne = model_dimreduce.fit_transform(_class)\n",
    "\n",
    "    _rep_tsne = scaler.fit_transform(_rep)\n",
    "    _class_tsne = scaler.transform(_class)\n",
    "    plt.title(\"Epoch {0}\".format((i * 250)), fontsize=20)\n",
    "    sns.scatterplot(x =_rep_tsne[:, 0], y = _rep_tsne[:, 1], label = \"Representation\")\n",
    "    sns.scatterplot(x =_class_tsne[:, 0], y = _class_tsne[:, 1], marker = \"*\", label = \"Class prototypes\", s=100)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
