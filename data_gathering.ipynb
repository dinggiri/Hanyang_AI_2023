{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"gmCERNqmhgDb"},"source":["# Import Library"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting tqdm\n","  Downloading tqdm-4.65.0-py3-none-any.whl (77 kB)\n","Requirement already satisfied: colorama in c:\\users\\yuins\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from tqdm) (0.4.4)\n","Installing collected packages: tqdm\n","Successfully installed tqdm-4.65.0\n"]},{"name":"stderr","output_type":"stream","text":["WARNING: You are using pip version 21.0.1; however, version 23.1.2 is available.\n","You should consider upgrading via the 'C:\\Users\\yuins\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip' command.\n"]}],"source":["!pip install tqdm"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1685183218751,"user":{"displayName":"유승길","userId":"05500352468646597729"},"user_tz":-540},"id":"H7K1NeUjrDLj"},"outputs":[],"source":["import datetime\n","import os\n","import time\n","import zipfile\n","from tqdm import tqdm\n","\n","import requests\n","# import yaml"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"jHlaiNXBhkfh"},"source":["# Set path"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":30109,"status":"ok","timestamp":1685183248850,"user":{"displayName":"유승길","userId":"05500352468646597729"},"user_tz":-540},"id":"eLoPkOflpmop","outputId":"cb1f52cb-8f5d-4d06-d7f2-3a47dd2f14b7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":51,"status":"ok","timestamp":1685183248855,"user":{"displayName":"유승길","userId":"05500352468646597729"},"user_tz":-540},"id":"ckOrE3jiqjLx"},"outputs":[],"source":["path = \"/content/drive/MyDrive/2023_AI/data/\""]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":54,"status":"ok","timestamp":1685183248859,"user":{"displayName":"유승길","userId":"05500352468646597729"},"user_tz":-540},"id":"O_JanASjre5w","outputId":"8bc5b8f9-6389-4081-d6ca-936e2b2cd92c"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/2023_AI\n"]}],"source":["%cd /content/drive/MyDrive/2023_AI/"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":49,"status":"ok","timestamp":1685183248860,"user":{"displayName":"유승길","userId":"05500352468646597729"},"user_tz":-540},"id":"GlUMqmVzrgzC","outputId":"d2358b65-c272-45b4-f26e-7ff4c533812e"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/drive/MyDrive/2023_AI'"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["%pwd"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"3ehU_FTdhnB3"},"source":["# DataSet Download\n","Referred https://github.com/saif-mahmud/self-attention-HAR/blob/main/configs/data.yaml"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1685183252772,"user":{"displayName":"유승길","userId":"05500352468646597729"},"user_tz":-540},"id":"QOpgRSk4h70y"},"outputs":[],"source":["# basic dictionary of data download\n","config = {'data_dir': {'raw' : 'data/raw', 'processed' : 'data\\processed'},\n","          'pamap2' : {'source' : 'https://archive.ics.uci.edu/ml/machine-learning-databases/00231/PAMAP2_Dataset.zip',\n","                      'destination' : 'pamap2.zip',\n","                      'train_files' : [ 'subject101.dat', 'subject102.dat', 'subject103.dat','subject104.dat', 'subject107.dat', 'subject108.dat', 'subject109.dat' ],\n","                      'validation_files' : [ 'subject105.dat' ],\n","                      'test_files' : [ 'subject106.dat' ],\n","                      'output_file': 'pamap2_106.h5',\n","                      'feature_columns' : [ 1, 4, 5, 6, 10, 11, 12, 21, 22, 23, 27, 28, 29, 38, 39, 40, 44, 45, 46 ],\n","                      'window_size' : 33\n","                      }}\n","           \n","#   raw: data/raw\n","#   processed: data/processed\n","\n","# pamap2:\n","#   source: https://archive.ics.uci.edu/ml/machine-learning-databases/00231/PAMAP2_Dataset.zip\n","#   destination: pamap2.zip\n","#   train_files: [ 'subject101.dat', 'subject102.dat', 'subject103.dat','subject104.dat', 'subject107.dat', 'subject108.dat', 'subject109.dat' ]\n","#   validation_files: [ 'subject105.dat' ]\n","#   test_files: [ 'subject106.dat' ]\n","#   output_file: 'pamap2_106.h5'\n","#   feature_columns: [ 1, 4, 5, 6, 10, 11, 12, 21, 22, 23, 27, 28, 29, 38, 39, 40, 44, 45, 46 ]\n","#   window_size: 33"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1685183254534,"user":{"displayName":"유승길","userId":"05500352468646597729"},"user_tz":-540},"id":"y90w43IENCDD"},"outputs":[],"source":["import argparse\n","import datetime\n","import os\n","import time\n","import zipfile\n","from tqdm import tqdm\n","\n","import requests\n","# import yaml\n","\n","\n","def get_dataset(url: str, data_directory: str, file_name: str, unzip: bool):\n","    if not os.path.exists('data/'):\n","        os.mkdir('data/')\n","\n","    print(datetime.datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S'))\n","\n","    if not os.path.exists(data_directory):\n","        os.makedirs(data_directory)\n","\n","    if not os.path.exists(os.path.join(data_directory, file_name)):\n","        print(f'GETTING DATASET [{file_name}] ...')\n","\n","        response = requests.get(url, stream=True)\n","        data_file = open(os.path.join(data_directory, file_name), 'wb')\n","\n","        total_size = int(response.headers.get(\"Content-Length\", 0))\n","        chunk_size = 1024\n","\n","        for chunk in tqdm(iterable=response.iter_content(chunk_size=chunk_size), total=total_size / chunk_size,\n","                          unit='KB', unit_scale=True, unit_divisor=chunk_size):\n","            data_file.write(chunk)\n","\n","        data_file.close()\n","\n","        if unzip:\n","            print(f'Unzipping [{file_name}] ...')\n","            with zipfile.ZipFile(os.path.join(data_directory, file_name), 'r') as zip_ref:\n","                zip_ref.extractall(os.path.join(data_directory, file_name.split('.')[0]))\n","                os.remove(os.path.join(data_directory, file_name))\n","\n","        print('\\n---DATASET DOWNLOAD COMPLETE---')\n","\n","    else:\n","        print(f'Requested dataset exists in {data_directory}')"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1685183256480,"user":{"displayName":"유승길","userId":"05500352468646597729"},"user_tz":-540},"id":"xTS3MyhfNnWN"},"outputs":[{"name":"stdout","output_type":"stream","text":["2023-05-27 19:33:36\n","GETTING DATASET [pamap2.zip] ...\n"]},{"name":"stderr","output_type":"stream","text":["100%|█████████▉| 656k/656k [01:46<00:00, 6.72kKB/s] C:\\Users\\yuins\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tqdm\\std.py:524: TqdmWarning: clamping frac to range [0, 1]\n","  full_bar = Bar(frac,\n","100%|██████████| 656k/656k [01:46<00:00, 6.29kKB/s]\n"]},{"name":"stdout","output_type":"stream","text":["Unzipping [pamap2.zip] ...\n"]},{"ename":"PermissionError","evalue":"[WinError 32] 다른 프로세스가 파일을 사용 중이기 때문에 프로세스가 액세스 할 수 없습니다: 'data/raw\\\\pamap2.zip'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)","\u001b[1;32m<ipython-input-7-d7bb3608c226>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m get_dataset(url=config['pamap2']['source'], data_directory=config['data_dir']['raw'],\n\u001b[0m\u001b[0;32m      2\u001b[0m                 file_name=config['pamap2']['destination'], unzip=True)\n","\u001b[1;32m<ipython-input-6-9fd522709063>\u001b[0m in \u001b[0;36mget_dataset\u001b[1;34m(url, data_directory, file_name, unzip)\u001b[0m\n\u001b[0;32m     38\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_directory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mzip_ref\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m                 \u001b[0mzip_ref\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_directory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m                 \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_directory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\n---DATASET DOWNLOAD COMPLETE---'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mPermissionError\u001b[0m: [WinError 32] 다른 프로세스가 파일을 사용 중이기 때문에 프로세스가 액세스 할 수 없습니다: 'data/raw\\\\pamap2.zip'"]}],"source":["get_dataset(url=config['pamap2']['source'], data_directory=config['data_dir']['raw'],\n","                file_name=config['pamap2']['destination'], unzip=True)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"UDkWH5xvKQlG"},"source":["# Reading Data"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1685183260205,"user":{"displayName":"유승길","userId":"05500352468646597729"},"user_tz":-540},"id":"3X3y6rtLKP8b"},"outputs":[],"source":["import csv\n","import os\n","\n","import h5py #  매우 크고 복잡한 대용량 데이터를 저장하기 위한 파일 형식\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","plt.style.use('ggplot')\n","\n","\n","class data_reader: \n","    def __init__(self, train_test_files, use_columns, output_file_name):\n","        if not os.path.exists(output_file_name): # output file name\n","            self.data, self.idToLabel = self.readPamap2(train_test_files, use_columns)\n","            self.save_data(output_file_name)\n","\n","    def save_data(self, output_file_name):\n","        print(output_file_name)\n","        f = h5py.File(output_file_name, 'w')\n","        for key in self.data:\n","            f.create_group(key)\n","            for field in self.data[key]:\n","                f[key].create_dataset(field, data=self.data[key][field])\n","        f.close()\n","\n","    @property #getter\n","    def train(self):\n","        return self.data['train']\n","\n","    @property #getter\n","    def test(self):\n","        return self.data['test']\n","\n","    def readPamap2(self, train_test_files, use_columns):\n","        files = train_test_files\n","        label_map = [\n","            # (0, 'other'),\n","            (1, 'lying'),\n","            (2, 'sitting'),\n","            (3, 'standing'),\n","            (4, 'walking'),\n","            (5, 'running'),\n","            (6, 'cycling'),\n","            (7, 'Nordic walking'),\n","            (9, 'watching TV'),\n","            (10, 'computer work'),\n","            (11, 'car driving'),\n","            (12, 'ascending stairs'),\n","            (13, 'descending stairs'),\n","            (16, 'vacuum cleaning'),\n","            (17, 'ironing'),\n","            (18, 'folding laundry'),\n","            (19, 'house cleaning'),\n","            (20, 'playing soccer'),\n","            (24, 'rope jumping')\n","        ] # column과 그것에 해당하는 이름 작성\n","        labelToId = {str(x[0]): i for i, x in enumerate(label_map)} # 위의 것을 \"1(column label) : 0(부터 시작하는 인덱스 순서)로 바꾸는 딕셔너리 정의\"\n","        idToLabel = [x[1] for x in label_map] # Label들\n","        cols = use_columns\n","        data = {dataset: self.readPamap2Files(files[dataset], cols, labelToId)\n","                for dataset in ('train', 'test', 'validation')}\n","        return data, idToLabel\n","\n","    def readPamap2Files(self, filelist, cols, labelToId):\n","        data = []\n","        labels = []\n","        for i, filename in enumerate(filelist):\n","            # print('Reading file %d of %d' % (i + 1, len(filelist)))\n","            with open('data/raw/pamap2/PAMAP2_Dataset/Protocol/%s' % filename, 'r') as f:\n","                reader = csv.reader(f, delimiter=' ') # 읽어옴\n","                for line in reader:\n","                    elem = []\n","                    # not including the non related activity\n","                    if line[1] == \"0\": # others인 경우 넘어가기\n","                        continue\n","                    for ind in cols: \n","                        elem.append(line[ind])\n","                    if sum([x == 'NaN' for x in elem]) < 9:\n","                        data.append([float(x) / 1000 for x in elem[:-1]]) # data.append\n","                        labels.append(labelToId[elem[0]])\n","\n","        return {'inputs': np.asarray(data), 'targets': np.asarray(labels, dtype=int) + 1}\n","\n","\n","def read_dataset(train_test_files, use_columns, output_file_name):\n","    print('[Reading PAMAP2] ...')\n","    data_reader(train_test_files, use_columns, output_file_name)\n","    print('[Reading PAMAP2] : DONE')"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":520},"executionInfo":{"elapsed":70930,"status":"error","timestamp":1685183332197,"user":{"displayName":"유승길","userId":"05500352468646597729"},"user_tz":-540},"id":"6-Sg0ReYNmJD","outputId":"6a6caacf-6592-4ea3-93bf-24e071ddc592"},"outputs":[{"name":"stdout","output_type":"stream","text":["[Reading PAMAP2] ...\n","data\\processed\\pamap2_106.h5\n","[Reading PAMAP2] : DONE\n"]}],"source":["train_test_files = {'train': config['pamap2']['train_files'],\n","                    'validation': config['pamap2']['validation_files'],\n","                    'test': config['pamap2']['test_files']\n","                    }\n","\n","\n","read_dataset(train_test_files=train_test_files,\n","                use_columns=config['pamap2']['feature_columns'],\n","                output_file_name=os.path.join(config['data_dir']['processed'], config['pamap2']['output_file']))"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":485},"executionInfo":{"elapsed":460,"status":"error","timestamp":1685183180266,"user":{"displayName":"유승길","userId":"05500352468646597729"},"user_tz":-540},"id":"VcqBQGfvahX0","outputId":"139d4ca6-96a4-44eb-8c78-f5241971a299"},"outputs":[],"source":["path = os.path.join(config['data_dir']['processed'], config['pamap2']['output_file'])\n","f = h5py.File(path, 'r')\n","\n","x_train = f.get('train').get('inputs')[()]\n","y_train = f.get('train').get('targets')[()]\n","\n","x_val = f.get('validation').get('inputs')[()]\n","y_val = f.get('validation').get('targets')[()]\n","\n","x_test = f.get('test').get('inputs')[()]\n","y_test = f.get('test').get('targets')[()]"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"0W6iz9hovAjF"},"outputs":[],"source":["# replace nan with mean\n","x_train = np.where(np.isnan(x_train), np.ma.array(x_train, mask=np.isnan(x_train)).mean(axis=0), x_train)\n","x_val = np.where(np.isnan(x_val), np.ma.array(x_val, mask=np.isnan(x_val)).mean(axis=0), x_val)\n","x_test = np.where(np.isnan(x_test), np.ma.array(x_test, mask=np.isnan(x_test)).mean(axis=0), x_test)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"ename":"NameError","evalue":"name 'tf' is not defined","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[1;32m<ipython-input-26-9bd3d3291d05>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_categorical\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m19\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtest_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_categorical\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m19\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mval_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_categorical\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m19\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mNameError\u001b[0m: name 'tf' is not defined"]}],"source":["\n","train_y = tf.keras.utils.to_categorical(y_train, num_classes=19)\n","test_y = tf.keras.utils.to_categorical(y_test, num_classes=19)\n","val_y = tf.keras.utils.to_categorical(y_val, num_classes=19)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":26,"status":"aborted","timestamp":1685177344233,"user":{"displayName":"유승길","userId":"05500352468646597729"},"user_tz":-540},"id":"DO5f3E_hLlm-"},"outputs":[],"source":["import numpy as np\n","from scipy import stats\n","\n","def windowz(data, size, use_overlap=True):\n","    start = 0\n","    while start < len(data):\n","        yield start, start + size\n","        if use_overlap:\n","            start += (size // 2)\n","        else:\n","            start += size\n","\n","\n","def segment_pa2_test(x_test, y_test, window_size, n_sensor_val):\n","    segments = np.zeros(((len(x_test) // (window_size)) + 1, window_size, n_sensor_val))\n","    labels = np.zeros(((len(y_test) // (window_size)) + 1))\n","    i_segment = 0\n","    i_label = 0\n","    for (start, end) in windowz(x_test, window_size, use_overlap=False):\n","        if end >= x_test.shape[0]:\n","            pad_len = window_size - len(x_test[start:end])\n","            segments[i_segment] = x_test[start - pad_len:end]\n","            m = stats.mode(y_test[start - pad_len:end])\n","            labels[i_label] = m[0]\n","        else:\n","            m = stats.mode(y_test[start:end])\n","            segments[i_segment] = x_test[start:end]\n","            labels[i_label] = m[0]\n","            i_label += 1\n","            i_segment += 1\n","\n","    return segments, labels\n","\n","\n","def segment_pa2(x_train, y_train, window_size, n_sensor_val):\n","    segments = np.zeros(((len(x_train) // (window_size // 2)) - 1, window_size, n_sensor_val))\n","    labels = np.zeros(((len(y_train) // (window_size // 2)) - 1))\n","    i_segment = 0\n","    i_label = 0\n","    for (start, end) in windowz(x_train, window_size):\n","        if len(x_train[start:end]) == window_size:\n","            m = stats.mode(y_train[start:end])\n","            segments[i_segment] = x_train[start:end]\n","            labels[i_label] = m[0]\n","            i_label += 1\n","            i_segment += 1\n","    return segments, labels\n","\n","\n","def unsegment_pa2_test(y_preds, total_length, window_size):\n","    unsegmented_preds = np.zeros((total_length,))\n","    start = 0\n","    end = window_size\n","    for element in y_preds:\n","        if end >= total_length:\n","            end = total_length\n","        for i in range(start, end):\n","            unsegmented_preds[i] = element\n","        start = end\n","        end += window_size\n","        # print(start, end)\n","    return unsegmented_preds\n","\n","\n","def segment_window_all(x_train, y_train, window_size, n_sensor_val):\n","    window_segments = np.zeros((len(x_train), window_size, n_sensor_val))\n","    labels = np.zeros((len(y_train),))\n","\n","    total_len = len(x_train)\n","\n","    for i in range(total_len):\n","        end = i + window_size\n","\n","        if end > total_len:\n","            pad_len = end - total_len\n","            window_segments[i] = x_train[i - pad_len:end]\n","            labels[i] = y_train[total_len - 1]\n","        else:\n","            window_segments[i] = x_train[i:end]\n","            labels[i] = y_train[end - 1]\n","\n","    return window_segments, labels"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":28,"status":"aborted","timestamp":1685177344235,"user":{"displayName":"유승길","userId":"05500352468646597729"},"user_tz":-540},"id":"QAe7jXXTLmE4"},"outputs":[],"source":["import os\n","\n","import h5py\n","import numpy as np\n","import tensorflow as tf\n","import yaml\n","\n","# from ._data_reader import read_dataset\n","# from ._sliding_window import segment_pa2, segment_window_all\n","\n","\n","def get_pamap2_data(verbose=False):\n","    config_file = open('configs/data.yaml', mode='r')\n","    data_config = yaml.load(config_file, Loader=yaml.FullLoader)\n","    config = data_config['pamap2']\n","\n","    train_test_files = {'train': config['train_files'],\n","                        'validation': config['validation_files'],\n","                        'test': config['test_files']\n","                        }\n","\n","    read_dataset(train_test_files=train_test_files,\n","                 use_columns=config['feature_columns'],\n","                 output_file_name=os.path.join(data_config['data_dir']['processed'], config['output_file']))\n","\n","    path = os.path.join(data_config['data_dir']['processed'], config['output_file'])\n","    f = h5py.File(path, 'r')\n","\n","    x_train = f.get('train').get('inputs')[()]\n","    y_train = f.get('train').get('targets')[()]\n","\n","    x_val = f.get('validation').get('inputs')[()]\n","    y_val = f.get('validation').get('targets')[()]\n","\n","    x_test = f.get('test').get('inputs')[()]\n","    y_test = f.get('test').get('targets')[()]\n","\n","    if verbose:\n","        print(\"x_train shape = \", x_train.shape)\n","        print(\"y_train shape =\", y_train.shape)\n","\n","        print(\"x_val shape = \", x_val.shape)\n","        print(\"y_val shape =\", y_val.shape)\n","\n","        print(\"x_test shape =\", x_test.shape)\n","        print(\"y_test shape =\", y_test.shape)\n","\n","    x_train = x_train[::3, :]\n","    y_train = y_train[::3]\n","    x_val = x_val[::3, :]\n","    y_val = y_val[::3]\n","    x_test = x_test[::3, :]\n","    y_test = y_test[::3]\n","\n","    if verbose:\n","        print(\"x_train shape(downsampled) = \", x_train.shape)\n","        print(\"y_train shape(downsampled) =\", y_train.shape)\n","        print(\"x_val shape(downsampled) = \", x_val.shape)\n","        print(\"y_val shape(downsampled) =\", y_val.shape)\n","        print(\"x_test shape(downsampled) =\", x_test.shape)\n","        print(\"y_test shape(downsampled) =\", y_test.shape)\n","\n","    # replace nan with mean\n","    x_train = np.where(np.isnan(x_train), np.ma.array(x_train, mask=np.isnan(x_train)).mean(axis=0), x_train)\n","    x_val = np.where(np.isnan(x_val), np.ma.array(x_val, mask=np.isnan(x_val)).mean(axis=0), x_val)\n","    x_test = np.where(np.isnan(x_test), np.ma.array(x_test, mask=np.isnan(x_test)).mean(axis=0), x_test)\n","\n","    n_sensor_val = len(config['feature_columns']) - 1\n","    train_x, train_y = segment_pa2(x_train, y_train, config['window_size'], n_sensor_val)\n","    val_x, val_y = segment_pa2(x_val, y_val, config['window_size'], n_sensor_val)\n","    test_x, test_y = segment_window_all(x_test, y_test, config['window_size'], n_sensor_val)\n","\n","    if verbose:\n","        print(\"train_x shape =\", train_x.shape)\n","        print(\"train_y shape =\", train_y.shape)\n","        print('train_y distribution', np.unique(train_y, return_counts=True))\n","\n","        print(\"val_x shape =\", val_x.shape)\n","        print(\"val_y shape =\", val_y.shape)\n","        print('val_y distribution', np.unique(val_y, return_counts=True))\n","\n","        print(\"test_x shape =\", test_x.shape)\n","        print(\"test_y shape =\", test_y.shape)\n","        print('test_y distribution', np.unique(test_y, return_counts=True))\n","\n","    train_y = tf.keras.utils.to_categorical(train_y, num_classes=19)\n","    test_y = tf.keras.utils.to_categorical(test_y, num_classes=19)\n","    val_y = tf.keras.utils.to_categorical(val_y, num_classes=19)\n","\n","    if verbose:\n","        print(\"unique test_y\", np.unique(test_y))\n","        print(\"unique train_y\", np.unique(train_y))\n","        print(\"test_y[1]=\", test_y[1])\n","\n","        print(\"train_y shape(1-hot) =\", train_y.shape)\n","        print(\"val_y shape(1-hot) =\", val_y.shape)\n","        print(\"test_y shape(1-hot) =\", test_y.shape)\n","\n","    return (train_x, train_y), (val_x, val_y), (test_x, test_y), y_test"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":46,"status":"aborted","timestamp":1685176668605,"user":{"displayName":"유승길","userId":"05500352468646597729"},"user_tz":-540},"id":"ZP0MrtlRLslH"},"outputs":[],"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPWrxoV2gMAirxmvwhc0SVp","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"}},"nbformat":4,"nbformat_minor":0}
